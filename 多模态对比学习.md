[TOC]



# 从零开始搭建虚拟环境

## MCSE: Multimodal Contrastive Learning of Sentence Embeddings

引入多模态对比学习来增强句子特征学习

## On the Difference of BERT-style and CLIP-style Text Encoders

# Training with Ontology-Informed Contrastive Sampling

## Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality 

## When and why vision-language models behave like bags-of-words, and what to do about it? 



//关于语序和图像理解的一些想法

很多文章都提到了细粒度语义 空间关系 并且是基于clip的改进（在对语序关系的敏感度上，可能是bert-based model表现会优于transformer-based）

Robust Contrastive Language-Image Pretraining against Adversarial Attacks         有一个图像和文本的池

HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention

//有代码的具体实现
